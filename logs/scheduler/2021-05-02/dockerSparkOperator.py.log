[2021-05-02 11:20:05,906] {scheduler_job.py:182} INFO - Started process (PID=28) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:20:05,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:20:05,909] {logging_mixin.py:104} INFO - [2021-05-02 11:20:05,909] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:20:05,974] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:20:05,998] {logging_mixin.py:104} INFO - [2021-05-02 11:20:05,998] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:20:06,007] {logging_mixin.py:104} INFO - [2021-05-02 11:20:06,006] {dag.py:1837} INFO - Creating ORM DAG for docker_spark_sample
[2021-05-02 11:20:06,011] {logging_mixin.py:104} INFO - [2021-05-02 11:20:06,011] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:20:06,024] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.123 seconds
[2021-05-02 11:20:36,258] {scheduler_job.py:182} INFO - Started process (PID=34) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:20:36,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:20:36,260] {logging_mixin.py:104} INFO - [2021-05-02 11:20:36,260] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:20:36,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:20:36,341] {logging_mixin.py:104} INFO - [2021-05-02 11:20:36,341] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:20:36,354] {logging_mixin.py:104} INFO - [2021-05-02 11:20:36,354] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:20:36,399] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.144 seconds
[2021-05-02 11:21:06,688] {scheduler_job.py:182} INFO - Started process (PID=40) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:21:06,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:21:06,691] {logging_mixin.py:104} INFO - [2021-05-02 11:21:06,691] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:21:06,753] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:21:06,774] {logging_mixin.py:104} INFO - [2021-05-02 11:21:06,774] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:21:06,787] {logging_mixin.py:104} INFO - [2021-05-02 11:21:06,787] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:21:06,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.108 seconds
[2021-05-02 11:21:37,083] {scheduler_job.py:182} INFO - Started process (PID=51) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:21:37,085] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:21:37,086] {logging_mixin.py:104} INFO - [2021-05-02 11:21:37,086] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:21:37,145] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:21:37,165] {logging_mixin.py:104} INFO - [2021-05-02 11:21:37,165] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:21:37,179] {logging_mixin.py:104} INFO - [2021-05-02 11:21:37,179] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:21:37,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.106 seconds
[2021-05-02 11:22:07,481] {scheduler_job.py:182} INFO - Started process (PID=57) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:22:07,483] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:22:07,484] {logging_mixin.py:104} INFO - [2021-05-02 11:22:07,484] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:22:07,544] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:22:07,566] {logging_mixin.py:104} INFO - [2021-05-02 11:22:07,566] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:22:07,580] {logging_mixin.py:104} INFO - [2021-05-02 11:22:07,579] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:22:07,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.109 seconds
[2021-05-02 11:22:37,871] {scheduler_job.py:182} INFO - Started process (PID=63) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:22:37,872] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:22:37,874] {logging_mixin.py:104} INFO - [2021-05-02 11:22:37,873] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:22:37,930] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:22:37,950] {logging_mixin.py:104} INFO - [2021-05-02 11:22:37,950] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:22:37,963] {logging_mixin.py:104} INFO - [2021-05-02 11:22:37,963] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:22:37,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.102 seconds
[2021-05-02 11:23:08,285] {scheduler_job.py:182} INFO - Started process (PID=69) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:23:08,290] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:23:08,292] {logging_mixin.py:104} INFO - [2021-05-02 11:23:08,291] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:23:08,413] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:23:08,484] {logging_mixin.py:104} INFO - [2021-05-02 11:23:08,484] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:23:08,508] {logging_mixin.py:104} INFO - [2021-05-02 11:23:08,508] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:23:08,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.236 seconds
[2021-05-02 11:23:38,809] {scheduler_job.py:182} INFO - Started process (PID=75) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:23:38,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:23:38,811] {logging_mixin.py:104} INFO - [2021-05-02 11:23:38,811] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:23:38,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:23:38,891] {logging_mixin.py:104} INFO - [2021-05-02 11:23:38,891] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:23:38,906] {logging_mixin.py:104} INFO - [2021-05-02 11:23:38,906] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:23:38,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.107 seconds
[2021-05-02 11:24:09,214] {scheduler_job.py:182} INFO - Started process (PID=81) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:24:09,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:24:09,216] {logging_mixin.py:104} INFO - [2021-05-02 11:24:09,216] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:24:09,276] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:24:09,295] {logging_mixin.py:104} INFO - [2021-05-02 11:24:09,295] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:24:09,308] {logging_mixin.py:104} INFO - [2021-05-02 11:24:09,308] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:24:09,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.105 seconds
[2021-05-02 11:24:39,618] {scheduler_job.py:182} INFO - Started process (PID=87) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:24:39,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:24:39,621] {logging_mixin.py:104} INFO - [2021-05-02 11:24:39,620] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:24:39,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:24:39,712] {logging_mixin.py:104} INFO - [2021-05-02 11:24:39,712] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:24:39,725] {logging_mixin.py:104} INFO - [2021-05-02 11:24:39,725] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:24:39,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.118 seconds
[2021-05-02 11:25:10,098] {scheduler_job.py:182} INFO - Started process (PID=98) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:25:10,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:25:10,102] {logging_mixin.py:104} INFO - [2021-05-02 11:25:10,102] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:25:10,173] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:25:10,203] {logging_mixin.py:104} INFO - [2021-05-02 11:25:10,203] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:25:10,220] {logging_mixin.py:104} INFO - [2021-05-02 11:25:10,220] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:25:10,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.135 seconds
[2021-05-02 11:25:40,512] {scheduler_job.py:182} INFO - Started process (PID=104) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:25:40,514] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:25:40,515] {logging_mixin.py:104} INFO - [2021-05-02 11:25:40,515] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:25:40,577] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:25:40,600] {logging_mixin.py:104} INFO - [2021-05-02 11:25:40,600] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:25:40,612] {logging_mixin.py:104} INFO - [2021-05-02 11:25:40,612] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:25:40,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.109 seconds
[2021-05-02 11:26:10,905] {scheduler_job.py:182} INFO - Started process (PID=110) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:26:10,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:26:10,908] {logging_mixin.py:104} INFO - [2021-05-02 11:26:10,908] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:26:10,970] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:26:10,994] {logging_mixin.py:104} INFO - [2021-05-02 11:26:10,994] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:26:11,009] {logging_mixin.py:104} INFO - [2021-05-02 11:26:11,009] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:26:11,016] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.114 seconds
[2021-05-02 11:26:41,310] {scheduler_job.py:182} INFO - Started process (PID=116) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:26:41,312] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:26:41,313] {logging_mixin.py:104} INFO - [2021-05-02 11:26:41,313] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:26:41,374] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:26:41,393] {logging_mixin.py:104} INFO - [2021-05-02 11:26:41,393] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:26:41,406] {logging_mixin.py:104} INFO - [2021-05-02 11:26:41,406] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:26:41,413] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.106 seconds
[2021-05-02 11:27:11,768] {scheduler_job.py:182} INFO - Started process (PID=122) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:27:11,770] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:27:11,772] {logging_mixin.py:104} INFO - [2021-05-02 11:27:11,771] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:27:11,848] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:27:11,879] {logging_mixin.py:104} INFO - [2021-05-02 11:27:11,879] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:27:11,892] {logging_mixin.py:104} INFO - [2021-05-02 11:27:11,892] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:27:11,899] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.136 seconds
[2021-05-02 11:27:42,216] {scheduler_job.py:182} INFO - Started process (PID=133) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:27:42,218] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:27:42,219] {logging_mixin.py:104} INFO - [2021-05-02 11:27:42,219] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:27:42,301] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:27:42,327] {logging_mixin.py:104} INFO - [2021-05-02 11:27:42,326] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:27:42,349] {logging_mixin.py:104} INFO - [2021-05-02 11:27:42,348] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:27:42,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.144 seconds
[2021-05-02 11:28:12,667] {scheduler_job.py:182} INFO - Started process (PID=139) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:28:12,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:28:12,671] {logging_mixin.py:104} INFO - [2021-05-02 11:28:12,670] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:28:12,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:28:12,760] {logging_mixin.py:104} INFO - [2021-05-02 11:28:12,759] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:28:12,780] {logging_mixin.py:104} INFO - [2021-05-02 11:28:12,780] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:28:12,787] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.124 seconds
[2021-05-02 11:28:43,105] {scheduler_job.py:182} INFO - Started process (PID=145) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:28:43,107] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:28:43,108] {logging_mixin.py:104} INFO - [2021-05-02 11:28:43,108] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:28:43,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:28:43,197] {logging_mixin.py:104} INFO - [2021-05-02 11:28:43,197] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:28:43,212] {logging_mixin.py:104} INFO - [2021-05-02 11:28:43,212] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:28:43,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.117 seconds
[2021-05-02 11:29:13,576] {scheduler_job.py:182} INFO - Started process (PID=151) to work on /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:29:13,577] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/dockerSparkOperator.py for tasks to queue
[2021-05-02 11:29:13,579] {logging_mixin.py:104} INFO - [2021-05-02 11:29:13,578] {dagbag.py:448} INFO - Filling up the DagBag from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:29:13,639] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['docker_spark_sample']) retrieved from /opt/airflow/dags/dockerSparkOperator.py
[2021-05-02 11:29:13,663] {logging_mixin.py:104} INFO - [2021-05-02 11:29:13,663] {dag.py:1818} INFO - Sync 1 DAGs
[2021-05-02 11:29:13,679] {logging_mixin.py:104} INFO - [2021-05-02 11:29:13,679] {dag.py:2273} INFO - Setting next_dagrun for docker_spark_sample to 2021-04-30 00:00:00+00:00
[2021-05-02 11:29:13,686] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/dockerSparkOperator.py took 0.114 seconds
